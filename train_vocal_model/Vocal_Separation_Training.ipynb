{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocal Separation Model Training (BS-RoFormer)\n",
    "\n",
    "This notebook trains a state-of-the-art vocal separation model using the BS-RoFormer architecture.\n",
    "\n",
    "**Features:**\n",
    "- Band-Split RoPE Transformer for frequency-domain processing\n",
    "- State-of-the-art SDR (9.8+ dB on MUSDB18)\n",
    "- Can be fine-tuned for lead/backing vocal separation\n",
    "\n",
    "**Dataset:** MUSDB18-HQ (150 tracks, 10 hours)\n",
    "\n",
    "**Estimated time:** 24-48 hours on A100, 3-5 days on T4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install dependencies\n!pip install -q torch torchaudio einops rotary_embedding_torch wandb musdb museval soundfile\n!pip install -q git+https://github.com/facebookresearch/demucs.git"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone MVSEP training framework\n",
    "!git clone https://github.com/ZFTurbo/Music-Source-Separation-Training.git /content/mss_training\n",
    "%cd /content/mss_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download MUSDB18-HQ dataset\n",
    "import os\n",
    "import musdb\n",
    "\n",
    "MUSDB_PATH = '/content/musdb18hq'\n",
    "\n",
    "if not os.path.exists(MUSDB_PATH):\n",
    "    print(\"Downloading MUSDB18-HQ dataset...\")\n",
    "    print(\"This is a 7GB download and may take 10-20 minutes.\")\n",
    "    !pip install -q musdb\n",
    "    \n",
    "    # Download using musdb\n",
    "    mus = musdb.DB(root=MUSDB_PATH, download=True, is_wav=True)\n",
    "    print(f\"Downloaded {len(mus)} tracks\")\n",
    "else:\n",
    "    print(\"MUSDB18-HQ already downloaded\")\n",
    "    mus = musdb.DB(root=MUSDB_PATH, is_wav=True)\n",
    "    print(f\"Found {len(mus)} tracks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import yaml\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create config for BS-RoFormer vocal separation\n",
    "config = {\n",
    "    'audio': {\n",
    "        'chunk_size': 131072,  # ~3 seconds at 44.1kHz\n",
    "        'sample_rate': 44100,\n",
    "        'num_channels': 2,\n",
    "        'min_mean_abs': 0.001\n",
    "    },\n",
    "    'model': {\n",
    "        'type': 'bs_roformer',\n",
    "        'dim': 384,\n",
    "        'depth': 12,\n",
    "        'stereo': True,\n",
    "        'num_stems': 1,  # Vocals only (other = residual)\n",
    "        'time_transformer_depth': 1,\n",
    "        'freq_transformer_depth': 1,\n",
    "        'num_bands': 60,\n",
    "        'dim_head': 64,\n",
    "        'heads': 8,\n",
    "        'attn_dropout': 0.1,\n",
    "        'ff_dropout': 0.1,\n",
    "        'flash_attn': True,\n",
    "        'stft_n_fft': 2048,\n",
    "        'stft_hop_length': 512,\n",
    "    },\n",
    "    'training': {\n",
    "        'batch_size': 4,\n",
    "        'gradient_accumulation_steps': 4,\n",
    "        'num_epochs': 100,\n",
    "        'num_steps': 1000,\n",
    "        'lr': 5e-5,\n",
    "        'instruments': ['vocals', 'other'],\n",
    "        'target_instrument': 'vocals',\n",
    "        'use_amp': True,\n",
    "        'optimizer': 'adamw',\n",
    "    },\n",
    "    'augmentations': {\n",
    "        'enable': True,\n",
    "        'loudness': True,\n",
    "        'loudness_min': 0.5,\n",
    "        'loudness_max': 1.5,\n",
    "        'mixup': True,\n",
    "        'mixup_alpha': 0.4,\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save config\n",
    "config_path = '/content/mss_training/configs/config_vocals_bsroformer.yaml'\n",
    "with open(config_path, 'w') as f:\n",
    "    yaml.dump(config, f, default_flow_style=False)\n",
    "\n",
    "print(\"Config saved to:\", config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Prepare dataset in expected format\nimport shutil\nimport soundfile as sf\nfrom pathlib import Path\n\nTRAIN_DIR = Path('/content/musdb_training')\nTRAIN_DIR.mkdir(exist_ok=True)\n\nprint(\"Organizing dataset for training...\")\n\nmus = musdb.DB(root=MUSDB_PATH, is_wav=True, subsets='train')\n\nfor track in mus:\n    track_dir = TRAIN_DIR / track.name\n    track_dir.mkdir(exist_ok=True)\n    \n    # Save stems\n    # Vocals\n    sf.write(str(track_dir / 'vocals.wav'), track.targets['vocals'].audio, track.rate)\n    \n    # Other (everything except vocals)\n    other = track.targets['drums'].audio + track.targets['bass'].audio + track.targets['other'].audio\n    sf.write(str(track_dir / 'other.wav'), other, track.rate)\n    \n    # Mixture\n    sf.write(str(track_dir / 'mixture.wav'), track.audio, track.rate)\n\nprint(f\"Prepared {len(mus)} tracks for training\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Start training\nRESULTS_DIR = '/content/drive/MyDrive/vocal_model_results'\n!mkdir -p {RESULTS_DIR}\n\n!python train.py \\\n    --model_type bs_roformer \\\n    --config_path {config_path} \\\n    --data_path {TRAIN_DIR} \\\n    --results_path {RESULTS_DIR} \\\n    --dataset_type 1 \\\n    --device_ids 0 \\\n    --num_workers 0 \\\n    --pin_memory"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "import museval\n",
    "\n",
    "print(\"Evaluating model on MUSDB18 test set...\")\n",
    "\n",
    "# Load best model checkpoint\n",
    "checkpoints = list(Path(RESULTS_DIR).glob('*.ckpt'))\n",
    "if checkpoints:\n",
    "    best_ckpt = sorted(checkpoints, key=lambda x: x.stat().st_mtime)[-1]\n",
    "    print(f\"Using checkpoint: {best_ckpt}\")\n",
    "\n",
    "# Run evaluation\n",
    "!python inference.py \\\n",
    "    --model_type bs_roformer \\\n",
    "    --config_path {config_path} \\\n",
    "    --checkpoint {best_ckpt} \\\n",
    "    --input_folder {MUSDB_PATH}/test \\\n",
    "    --output_folder /content/eval_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List saved models\n",
    "print(\"Saved models:\")\n",
    "!ls -la {RESULTS_DIR}/*.ckpt 2>/dev/null || echo \"No checkpoints yet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Complete!\n",
    "\n",
    "Your trained vocal separation model is saved to `Google Drive/vocal_model_results/`\n",
    "\n",
    "**Expected Results:**\n",
    "- SDR (vocals): 9.5-10.0 dB on MUSDB18 test set\n",
    "- Much better than default Demucs (~8.5 dB)\n",
    "\n",
    "**Next Steps:**\n",
    "1. Copy model to StemScribe backend\n",
    "2. Update `enhanced_separator.py` to use it\n",
    "3. For lead/backing separation, fine-tune on songs with known stereo panning"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}