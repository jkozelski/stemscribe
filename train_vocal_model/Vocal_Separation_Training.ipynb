{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Vocal Separation Model ‚Äî BS-RoFormer (Pre-trained + Fine-tuning)\n\nThis notebook downloads a **state-of-the-art pre-trained BS-RoFormer** vocal separation model and optionally fine-tunes it.\n\n**Pre-trained model:** `model_bs_roformer_ep_317_sdr_12.9755.ckpt` (viperx edition)\n- **SDR (vocals): 12.97 dB** on MUSDB18 test set\n- Much better than training from scratch (~8-10 dB)\n- Based on ZFTurbo/Music-Source-Separation-Training framework\n\n**Why pre-trained?**\n- MUSDB18-HQ requires manual Zenodo access request\n- Training from scratch takes 24-48 hours on A100\n- Pre-trained model already achieves SOTA quality\n\n**Estimated time:** ~5 minutes to download model, save to Google Drive"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Check GPU\n!nvidia-smi"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Mount Google Drive\nfrom google.colab import drive\ndrive.mount('/content/drive')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install audio-separator (handles model download automatically)\n!pip install -q audio-separator[gpu] torch torchaudio\n\nimport torch\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Download pre-trained BS-RoFormer vocal separation model\n# This model achieves 12.97 SDR on MUSDB18 (state-of-the-art)\n# audio-separator will auto-download the checkpoint\n\nfrom audio_separator.separator import Separator\nimport os\n\n# Initialize separator with the best BS-RoFormer vocal model\n# This triggers automatic download of the model checkpoint (~350MB)\nprint(\"Downloading pre-trained BS-RoFormer vocal model...\")\nprint(\"Model: model_bs_roformer_ep_317_sdr_12.9755.ckpt\")\nprint(\"Expected SDR: 12.97 dB (vocals), 17.0 dB (instrumental)\")\n\nseparator = Separator(\n    model_file_dir='/content/models',\n    output_dir='/content/test_output'\n)\n\n# Load the BS-RoFormer model\nseparator.load_model(model_filename='model_bs_roformer_ep_317_sdr_12.9755.ckpt')\nprint(\"\\n‚úÖ Model downloaded and loaded successfully!\")\n\n# Show the downloaded model file\n!ls -lah /content/models/*.ckpt 2>/dev/null || echo \"Checking model location...\"\n!find /content/models -name \"*.ckpt\" -o -name \"*.pth\" -o -name \"*.pt\" 2>/dev/null | head -5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Quick test: Separate a sample audio to verify model works\n# Generate a short test signal (sine wave mix)\nimport numpy as np\nimport soundfile as sf\n\n# Create a simple test: vocal-like sine wave + drum-like noise\nsr = 44100\nduration = 3.0\nt = np.linspace(0, duration, int(sr * duration))\n\n# Fake \"vocal\" - smooth sine\nvocal = 0.5 * np.sin(2 * np.pi * 440 * t) * np.exp(-0.5 * t)\n# Fake \"drums\" - noise bursts\ndrums = 0.3 * np.random.randn(len(t)) * (np.sin(2 * np.pi * 2 * t) > 0.8)\nmix = np.column_stack([vocal + drums, vocal + drums])  # stereo\n\ntest_path = '/content/test_mix.wav'\nsf.write(test_path, mix, sr)\nprint(f\"Created test audio: {test_path}\")\n\n# Run separation\noutputs = separator.separate(test_path)\nprint(f\"\\n‚úÖ Separation test passed! Output files:\")\nfor f in outputs:\n    print(f\"  - {f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Save model to Google Drive for StemScribe integration\nimport shutil\nfrom pathlib import Path\n\nSAVE_DIR = Path('/content/drive/MyDrive/vocal_model_results')\nSAVE_DIR.mkdir(parents=True, exist_ok=True)\n\n# Find and copy the model checkpoint\nmodel_files = list(Path('/content/models').rglob('*.ckpt'))\nif not model_files:\n    model_files = list(Path('/content/models').rglob('*.pth'))\nif not model_files:\n    model_files = list(Path('/content/models').rglob('*.pt'))\n\n# Also look in the default audio-separator cache\nimport audio_separator\ncache_dir = Path(audio_separator.__file__).parent\nhome_models = Path.home() / '.cache'\n\n# Search common locations\nfor search_dir in ['/content/models', str(Path.home()), '/tmp']:\n    found = list(Path(search_dir).rglob('*bs_roformer*'))\n    if found:\n        model_files.extend(found)\n\nfor f in model_files:\n    dest = SAVE_DIR / f.name\n    if not dest.exists():\n        print(f\"Copying {f.name} ({f.stat().st_size / 1e6:.1f} MB) ‚Üí Google Drive...\")\n        shutil.copy2(str(f), str(dest))\n        print(f\"  ‚úÖ Saved to {dest}\")\n    else:\n        print(f\"  Already exists: {dest}\")\n\n# Also find and save the config file\nconfig_files = list(Path('/content/models').rglob('*.yaml'))\nfor f in config_files:\n    dest = SAVE_DIR / f.name\n    if not dest.exists():\n        shutil.copy2(str(f), str(dest))\n        print(f\"  ‚úÖ Config saved: {dest}\")\n\nprint(f\"\\nüìÅ Files in {SAVE_DIR}:\")\n!ls -lah {SAVE_DIR}/"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## Optional: Fine-tune on Custom Data\n\nIf you have your own vocal stems (e.g., from songs you've produced), you can fine-tune\nthe pre-trained model to better handle your specific music style.\n\n**Requirements:**\n- Folders with `vocals.wav` + `other.wav` (or `mixture.wav`)\n- Upload to Google Drive under `MyDrive/custom_vocal_data/`\n- Each song in its own subfolder\n\n**Fine-tuning benefits:**\n- Better handling of your specific genre/recording style\n- Improved separation on challenging passages\n- Only needs 10-50 songs and a few hours of training"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Optional: Fine-tune the pre-trained model on custom data\n# Skip this cell if you don't have custom training data\n\nimport os\nfrom pathlib import Path\n\nCUSTOM_DATA = Path('/content/drive/MyDrive/custom_vocal_data')\nFINETUNE = CUSTOM_DATA.exists() and any(CUSTOM_DATA.iterdir())\n\nif FINETUNE:\n    print(f\"Found custom data at {CUSTOM_DATA}\")\n    songs = [d for d in CUSTOM_DATA.iterdir() if d.is_dir()]\n    print(f\"Songs available for fine-tuning: {len(songs)}\")\n    for s in songs[:10]:\n        files = list(s.glob('*.wav'))\n        print(f\"  {s.name}: {len(files)} wav files\")\n    \n    # Install training dependencies\n    !pip install -q ml_collections omegaconf beartype protobuf==3.20.3\n    !pip install -q audiomentations torch_audiomentations auraloss\n    !git clone https://github.com/ZFTurbo/Music-Source-Separation-Training.git /content/mss_training 2>/dev/null || true\n    \n    # Find the downloaded model checkpoint path\n    model_ckpt = list(Path('/content/models').rglob('*bs_roformer*.ckpt'))\n    if model_ckpt:\n        ckpt_path = str(model_ckpt[0])\n        print(f\"\\nFine-tuning from checkpoint: {ckpt_path}\")\n    else:\n        print(\"‚ö†Ô∏è Could not find model checkpoint for fine-tuning\")\n        FINETUNE = False\nelse:\n    print(\"No custom data found at\", CUSTOM_DATA)\n    print(\"To fine-tune, create that folder and add song subfolders with vocals.wav + other.wav\")\n    print(\"\\nSkipping fine-tuning ‚Äî using pre-trained model as-is (12.97 SDR)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Fine-tuning (runs only if custom data was found above)\nif FINETUNE:\n    import yaml\n    \n    # Create fine-tuning config (lower learning rate, fewer epochs)\n    config = {\n        'audio': {\n            'chunk_size': 131072,\n            'sample_rate': 44100,\n            'num_channels': 2,\n            'min_mean_abs': 0.001\n        },\n        'model': {\n            'type': 'bs_roformer',\n            'dim': 384,\n            'depth': 12,\n            'stereo': True,\n            'num_stems': 1,\n            'time_transformer_depth': 1,\n            'freq_transformer_depth': 1,\n            'num_bands': 60,\n            'dim_head': 64,\n            'heads': 8,\n            'attn_dropout': 0.1,\n            'ff_dropout': 0.1,\n            'flash_attn': True,\n            'stft_n_fft': 2048,\n            'stft_hop_length': 512,\n        },\n        'training': {\n            'batch_size': 2,\n            'gradient_accumulation_steps': 8,\n            'num_epochs': 20,  # Fewer epochs for fine-tuning\n            'num_steps': 500,\n            'lr': 1e-5,  # Lower LR for fine-tuning\n            'instruments': ['vocals', 'other'],\n            'target_instrument': 'vocals',\n            'use_amp': True,\n            'optimizer': 'adamw',\n        },\n        'augmentations': {\n            'enable': True,\n            'loudness': True,\n            'loudness_min': 0.5,\n            'loudness_max': 1.5,\n        }\n    }\n    \n    config_path = '/content/mss_training/configs/config_finetune_vocals.yaml'\n    with open(config_path, 'w') as f:\n        yaml.dump(config, f, default_flow_style=False)\n    \n    RESULTS_DIR = '/content/drive/MyDrive/vocal_model_results/finetuned'\n    os.makedirs(RESULTS_DIR, exist_ok=True)\n    \n    %cd /content/mss_training\n    !python train.py \\\n        --model_type bs_roformer \\\n        --config_path {config_path} \\\n        --start_check_point {ckpt_path} \\\n        --data_path {CUSTOM_DATA} \\\n        --results_path {RESULTS_DIR} \\\n        --dataset_type 1 \\\n        --device_ids 0 \\\n        --num_workers 0 \\\n        --pin_memory\n    \n    print(f\"\\n‚úÖ Fine-tuning complete! Models saved to {RESULTS_DIR}\")\n    !ls -lah {RESULTS_DIR}/*.ckpt 2>/dev/null\nelse:\n    print(\"Skipping fine-tuning (no custom data)\")\n    print(\"Pre-trained model (12.97 SDR) is ready to use!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Summary: List all saved models\nfrom pathlib import Path\n\nSAVE_DIR = Path('/content/drive/MyDrive/vocal_model_results')\nprint(\"=\" * 60)\nprint(\"VOCAL SEPARATION MODEL - COMPLETE\")\nprint(\"=\" * 60)\n\n# List all models\nall_models = list(SAVE_DIR.rglob('*.ckpt')) + list(SAVE_DIR.rglob('*.pth')) + list(SAVE_DIR.rglob('*.pt'))\nif all_models:\n    print(f\"\\nüìÅ Models saved to Google Drive ({SAVE_DIR}):\")\n    for m in all_models:\n        size_mb = m.stat().st_size / 1e6\n        print(f\"  ‚úÖ {m.name} ({size_mb:.1f} MB)\")\nelse:\n    print(\"\\n‚ö†Ô∏è No model files found in Google Drive. Check the download step above.\")\n\nprint(\"\\nüìã Next steps:\")\nprint(\"  1. Download model from Google Drive to stemscribe/backend/models/pretrained/\")\nprint(\"  2. Update enhanced_separator.py to use the BS-RoFormer checkpoint\")\nprint(\"  3. Test vocal separation quality on real songs\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Done!\n\n**Pre-trained BS-RoFormer vocal model** saved to Google Drive.\n\n| Metric | Value |\n|--------|-------|\n| Model | BS-RoFormer (viperx ep317) |\n| SDR (vocals) | 12.97 dB |\n| SDR (instrumental) | 17.0 dB |\n| Architecture | Band-Split RoPE Transformer |\n| Parameters | ~350MB checkpoint |\n\n**To fine-tune later:**\n1. Upload vocal stems to `Google Drive/custom_vocal_data/<song_name>/vocals.wav + other.wav`\n2. Re-run this notebook ‚Äî it will automatically detect the custom data and fine-tune"
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}